{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 1: Linear Algebra and Probability.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dsvalencias/MachineLearning/blob/main/Assignment_1_Linear_Algebra_and_Probability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WVHdjQjZQRI"
      },
      "source": [
        "**Assignment 1: Linear Algebra and Probability**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glTLkx8MXQKm"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vACsZuN9STP-"
      },
      "source": [
        "TD = np.array([[2, 3, 0, 3, 7],\n",
        "              [0, 5, 5, 0, 3],\n",
        "              [5, 0, 7, 3, 3],\n",
        "              [3, 1, 0, 9, 9],\n",
        "              [0, 0, 7, 1, 3],\n",
        "              [6, 9, 4, 6, 0]])\n",
        "L = np.array([5, 2, 3, 6, 4, 3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HU-RydxqUjIE",
        "outputId": "4913d971-7300-4276-d097-7b14501f38ae"
      },
      "source": [
        "print(\"TD\")\n",
        "print(TD)\n",
        "print(\"L\")\n",
        "print(L)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TD\n",
            "[[2 3 0 3 7]\n",
            " [0 5 5 0 3]\n",
            " [5 0 7 3 3]\n",
            " [3 1 0 9 9]\n",
            " [0 0 7 1 3]\n",
            " [6 9 4 6 0]]\n",
            "L\n",
            "[5 2 3 6 4 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vXzGva_lvTO"
      },
      "source": [
        "First, TD matrix is representing the amount of ocurrencies of a word in every document. So, we have to normalize it respecting the probability proportional to the frequency of t_i in d_j\n",
        "In other words.\n",
        "\n",
        "${P(D,T)} = {P(T|D)} * {P(D)}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4L5nrg0Bdui"
      },
      "source": [
        "def partA(TD):\n",
        "  #Getting D probabilites\n",
        "  T_shape, D_shape = np.shape(TD)\n",
        "  D_probability = np.ones(D_shape) * 1 / D_shape\n",
        "  #Get occurrencies of every word in each document ( column )\n",
        "  T_sum_D = np.sum(TD, axis=0)\n",
        "  T_probability_in_D = np.divide(TD, T_sum_D)\n",
        "  #Divide each word ocurrence in each document ( position ) by all occurencies in a doc\n",
        "  T_D_prob = np.multiply(T_probability_in_D, D_probability)\n",
        "  return T_D_prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rzwt19cWB4fY",
        "outputId": "327b7aae-9192-427d-f819-828becef7558"
      },
      "source": [
        "T_D_prob = partA(TD)\n",
        "print(\"P(T,D)=\\n%s\" % T_D_prob)\n",
        "#The sum of probabilities of choosing a word in a document must be 1.0\n",
        "print(\"Sum of P(T,D)= %s\" % np.sum(T_D_prob))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "P(T,D)=\n",
            "[[0.025      0.03333333 0.         0.02727273 0.056     ]\n",
            " [0.         0.05555556 0.04347826 0.         0.024     ]\n",
            " [0.0625     0.         0.06086957 0.02727273 0.024     ]\n",
            " [0.0375     0.01111111 0.         0.08181818 0.072     ]\n",
            " [0.         0.         0.06086957 0.00909091 0.024     ]\n",
            " [0.075      0.1        0.03478261 0.05454545 0.        ]]\n",
            "Sum of P(T,D)= 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHBfin80WxMj"
      },
      "source": [
        "Now, we must use the Bayes theorem in order to find P(T|D)\n",
        "\n",
        "${P(T|D)} = {P(D,T)} / {P(D)}$\n",
        "\n",
        "Since we got P(D,T) in Part A and P(D) is an array of 0.2 (it will be shown in Part D) since docs has an uniform distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nlh8RhPFCY07"
      },
      "source": [
        "def partB(TD):\n",
        "  #Part B\n",
        "  T_shape, D_shape = np.shape(TD)\n",
        "  D_probability = np.ones(D_shape) * 1 / D_shape\n",
        "  T_given_D_prob = np.divide(T_D_prob, D_probability)\n",
        "  return T_given_D_prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSzsfrYRCpep",
        "outputId": "248053b8-6aa1-42a1-9b67-5d8b6d633056"
      },
      "source": [
        "T_given_D_prob = partB(TD)\n",
        "print(\"P(T|D)= %s\" % T_given_D_prob)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "P(T|D)= [[0.125      0.16666667 0.         0.13636364 0.28      ]\n",
            " [0.         0.27777778 0.2173913  0.         0.12      ]\n",
            " [0.3125     0.         0.30434783 0.13636364 0.12      ]\n",
            " [0.1875     0.05555556 0.         0.40909091 0.36      ]\n",
            " [0.         0.         0.30434783 0.04545455 0.12      ]\n",
            " [0.375      0.5        0.17391304 0.27272727 0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GneP5zL6oHp9",
        "outputId": "ff7a6164-4b95-4583-8826-0ad00a92bc86"
      },
      "source": [
        "T_given_D_prob.sum(axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lRHIP_ZfKjj"
      },
      "source": [
        "In a similar fashion we can obtain P(D|T) and the process of getting P(T) will be shown in part E\n",
        "\n",
        "${P(D|T)} = {P(D,T)} / {P(T)}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsLqjfNwDE6Y"
      },
      "source": [
        "def partC(TD):\n",
        "  T_count = np.sum(TD)\n",
        "  t_sum = np.sum(TD, axis=1)\n",
        "  #Divide by the total count of words\n",
        "  T_probability = np.divide(t_sum, T_count)\n",
        "  print(T_D_prob)\n",
        "  print(T_probability)\n",
        "  D_given_T_prob = np.divide(T_D_prob.transpose(), T_probability)\n",
        "  return D_given_T_prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "al6W6WzkEFEh",
        "outputId": "de6511b9-ee6f-44b1-e83a-1ae925913965"
      },
      "source": [
        "D_given_T_prob = partC(TD)\n",
        "print(\"P(D|T))= %s\" % D_given_T_prob.transpose())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.025      0.03333333 0.         0.02727273 0.056     ]\n",
            " [0.         0.05555556 0.04347826 0.         0.024     ]\n",
            " [0.0625     0.         0.06086957 0.02727273 0.024     ]\n",
            " [0.0375     0.01111111 0.         0.08181818 0.072     ]\n",
            " [0.         0.         0.06086957 0.00909091 0.024     ]\n",
            " [0.075      0.1        0.03478261 0.05454545 0.        ]]\n",
            "[0.14423077 0.125      0.17307692 0.21153846 0.10576923 0.24038462]\n",
            "P(D|T))= [[0.17333333 0.23111111 0.         0.18909091 0.38826667]\n",
            " [0.         0.44444444 0.34782609 0.         0.192     ]\n",
            " [0.36111111 0.         0.35169082 0.15757576 0.13866667]\n",
            " [0.17727273 0.05252525 0.         0.38677686 0.34036364]\n",
            " [0.         0.         0.57549407 0.08595041 0.22690909]\n",
            " [0.312      0.416      0.14469565 0.22690909 0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKrnU9n8YK4w"
      },
      "source": [
        "Since TD has a m x n shape and both T and D are vectors then:\n",
        "*   T must have a mx1 shape; m = 6\n",
        "*   D must have a 1xn shape; n = 5\n",
        "\n",
        "Now, D has an uniform probability function therefore, D must have 1/n probability or 1/5\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkbOl68iEQTb"
      },
      "source": [
        "def partD(TD):\n",
        "  T_shape, D_shape = np.shape(TD)\n",
        "  #print(D_shape)\n",
        "  D_probability = np.ones(D_shape) * 1 / D_shape\n",
        "  return D_probability"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBZKc8ucFoQP",
        "outputId": "bc8cec33-0e7a-4659-a205-4827bcbb6610"
      },
      "source": [
        "D_probability = partD(TD)\n",
        "print(\"P(D)= %s\" % D_probability)\n",
        "print(\"Sum of P(D)= %s\" % np.sum(D_probability))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "P(D)= [0.2 0.2 0.2 0.2 0.2]\n",
            "Sum of P(D)= 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyFiDAsMa3qK"
      },
      "source": [
        "In this part, P(T) depends on the posibility of every word and it can be infered using the amount of occurrencies row of TD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0hI4MpHF12_"
      },
      "source": [
        "def partE(TD):\n",
        "  T_count = np.sum(TD)\n",
        "  #Get total amount of word occurrencies \n",
        "  t_sum = np.sum(TD, axis=1)\n",
        "  #Divide by the total count of words\n",
        "  T_probability = np.divide(t_sum, T_count)\n",
        "  return T_probability"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiEyWl__F7b_",
        "outputId": "51071478-f352-4586-a9e4-764e751ba185"
      },
      "source": [
        "T_probability = partE(TD)\n",
        "print(\"P(T)= %s\" % T_probability)\n",
        "print(\"Sum of P(T)= %s\" % np.sum(T_probability))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "P(T)= [0.14423077 0.125      0.17307692 0.21153846 0.10576923 0.24038462]\n",
            "Sum of P(T)= 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHvfKrL-tZFl"
      },
      "source": [
        "In this part, E[l] is the expected value of the random variable l corresponding to the length of a randomly chosen term. l in this case is a discrete variable cause words can't have float characters. So in this case we use this formula\n",
        "\n",
        "$\\mu = \\operatorname{E}[X] = \\sum_{i=1}^n p_i x_i$\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxwFXmgDGMRB"
      },
      "source": [
        "def partF(TD):\n",
        "  #Multiply lengths of words with their probability itself\n",
        "  L_Expected_Vector = np.multiply(L, T_probability)\n",
        "  #Realize the summation\n",
        "  L_Expected_Value = np.sum(L_Expected_Vector)\n",
        "  return L_Expected_Value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9XMRG6RGVn5",
        "outputId": "94058ffb-ffa2-489b-c238-54a0142e05b8"
      },
      "source": [
        "L_Expected_Value = partF(TD)\n",
        "print(\"E[L]= %s\" % L_Expected_Value)\n",
        "print(np.average(L))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E[L]= 3.9038461538461533\n",
            "3.8333333333333335\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txOnMb4C4X39"
      },
      "source": [
        "In this part, Var(l) is the variance of the random variable l. Is the expectation of the squared deviation of a random variable from its mean.\n",
        "\n",
        "$\\operatorname{Var}(X) = \\sum_{i=1}^n p_i\\cdot(x_i - \\mu)^2$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-56pYteGe5C"
      },
      "source": [
        "def partG(TD):\n",
        "  #Substract lenghts with expected value of l\n",
        "  var_aux = L - L_Expected_Value\n",
        "  #Power them by 2\n",
        "  var_aux = np.power(var_aux,2)\n",
        "  #Multiply them with their probability itself\n",
        "  L_Variance_Vector = np.multiply(var_aux, T_probability)\n",
        "  L_Variance_Value = np.sum(L_Variance_Vector)\n",
        "  return L_Variance_Value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lITsTMbRoubF",
        "outputId": "703ac2a8-7ec3-4cec-c220-aa640fca1600"
      },
      "source": [
        "print(\"L con numpy\")\n",
        "print(np.var(L,ddof=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "L con numpy\n",
            "2.166666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rvj74bMwGnWr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aecddcf8-87b3-46ff-82b2-51eef6cec7d9"
      },
      "source": [
        "L_Variance_Value = partG(TD)\n",
        "print(\"Var(L)= %s\" % L_Variance_Value)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Var(L)= 1.8946005917159765\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}